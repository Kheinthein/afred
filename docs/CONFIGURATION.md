# Configuration - Alfred

Guide de configuration complet pour Alfred.

## Variables d'Environnement

### Base de Donn√©es

```env
# SQLite local (d√©veloppement)
DATABASE_URL="file:./dev.db"

# PostgreSQL (production)
DATABASE_URL="postgresql://user:password@localhost:5432/alfred"
```

---

## Configuration IA (Provider)

Alfred supporte **4 providers IA diff√©rents** gr√¢ce au pattern Adapter. Choisissez celui qui vous convient :

### 1. OpenAI (ChatGPT) - **Par D√©faut** ‚úÖ

**Avantages :**
- Qualit√© excellente
- Mod√®les vari√©s (GPT-4, GPT-3.5)
- API stable et bien document√©e
- Bon en fran√ßais

**Configuration :**
```env
AI_PROVIDER=openai
OPENAI_API_KEY=sk-votre-cl√©-ici
OPENAI_MODEL=gpt-4-turbo
```

**Obtenir une cl√© :**
1. Cr√©er un compte sur https://platform.openai.com/
2. Aller dans API Keys : https://platform.openai.com/api-keys
3. Cliquer "Create new secret key"
4. Copier la cl√© (format : `sk-...`)

**Mod√®les disponibles :**
- `gpt-4-turbo` : Le plus puissant (recommand√©)
- `gpt-4` : Tr√®s bon, un peu plus lent
- `gpt-3.5-turbo` : Rapide et moins cher

**Co√ªt approximatif :**
- GPT-4 Turbo : ~$0.01/analyse
- GPT-3.5 Turbo : ~$0.001/analyse

---

### 2. Claude (Anthropic)

**Avantages :**
- Excellent en fran√ßais
- Context window 200k tokens (tr√®s long)
- Bon √©quilibre qualit√©/prix

**Configuration :**
```env
AI_PROVIDER=claude
ANTHROPIC_API_KEY=sk-ant-votre-cl√©-ici
CLAUDE_MODEL=claude-3-5-sonnet-20241022
```

**Obtenir une cl√© :**
1. S'inscrire sur https://console.anthropic.com/
2. Aller dans API Keys
3. Cr√©er une nouvelle cl√©

**Mod√®les disponibles :**
- `claude-3-5-sonnet-20241022` : Meilleur rapport qualit√©/prix
- `claude-3-opus-20240229` : Plus puissant mais cher
- `claude-3-haiku-20240307` : Rapide et √©conomique

---

### 3. Mistral AI

**Avantages :**
- Fran√ßais natif (entreprise fran√ßaise)
- Bon rapport qualit√©/prix
- API simple

**Configuration :**
```env
AI_PROVIDER=mistral
MISTRAL_API_KEY=votre-cl√©-ici
MISTRAL_MODEL=mistral-large-latest
```

**Obtenir une cl√© :**
https://console.mistral.ai/

**Mod√®les disponibles :**
- `mistral-large-latest` : Le plus puissant
- `mistral-medium-latest` : Bon √©quilibre
- `mistral-small-latest` : Rapide et √©conomique

---

### 4. Ollama (Local, Gratuit) üÜì

**Avantages :**
- 100% gratuit
- Donn√©es restent en local (priv√©)
- Pas besoin d'API key
- Fonctionne offline

**Configuration :**
```env
AI_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1
```

**Installation :**

1. T√©l√©charger Ollama : https://ollama.ai/download

2. Installer un mod√®le :
```bash
# Llama 3.1 (recommand√©)
ollama pull llama3.1

# Alternatives
ollama pull mistral
ollama pull codellama
```

3. D√©marrer Ollama :
```bash
ollama serve
```

**Note :** Ollama est plus lent que les services cloud mais gratuit et priv√©.

---

## Configuration JWT

```env
# Secret pour signer les tokens JWT (CHANGEZ EN PRODUCTION !)
JWT_SECRET=votre-secret-tr√®s-s√©curis√©-changez-moi

# Dur√©e de validit√© des tokens
JWT_EXPIRES_IN=7d
```

**G√©n√©rer un secret s√©curis√© :**
```bash
# M√©thode 1 : OpenSSL
openssl rand -base64 32

# M√©thode 2 : Node.js
node -e "console.log(require('crypto').randomBytes(32).toString('base64'))"
```

---

## Configuration Rate Limiting

```env
# Fen√™tre de temps pour le rate limiting (en ms)
RATE_LIMIT_WINDOW_MS=900000  # 15 minutes

# Nombre max de requ√™tes par fen√™tre
RATE_LIMIT_MAX_REQUESTS=100

# Rate limit sp√©cifique pour les endpoints IA
AI_RATE_LIMIT_MAX_REQUESTS=10
```

---

## Configuration Logging

```env
# Niveau de log (error, warn, info, debug)
LOG_LEVEL=info

# En production, utilisez "warn" ou "error"
LOG_LEVEL=warn
```

---

## Configuration Next.js

```env
# URL publique de l'API
NEXT_PUBLIC_API_URL=http://localhost:3000

# En production
NEXT_PUBLIC_API_URL=https://votre-domaine.com
```

---

## Exemples de Configuration par Environnement

### D√©veloppement Local

```env
DATABASE_URL="file:./dev.db"
AI_PROVIDER=ollama  # Gratuit pour dev
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1
JWT_SECRET=dev-secret-not-for-production
NODE_ENV=development
LOG_LEVEL=debug
```

### Staging

```env
DATABASE_URL="file:./staging.db"
AI_PROVIDER=openai
OPENAI_API_KEY=sk-staging-key
OPENAI_MODEL=gpt-3.5-turbo  # Moins cher pour tests
JWT_SECRET=staging-secret-change-me
NODE_ENV=staging
LOG_LEVEL=info
```

### Production

```env
DATABASE_URL="postgresql://user:pass@db.example.com:5432/alfred"
AI_PROVIDER=openai
OPENAI_API_KEY=sk-prod-key-secure
OPENAI_MODEL=gpt-4-turbo  # Qualit√© max
JWT_SECRET=production-secret-very-secure-change-me
NODE_ENV=production
LOG_LEVEL=warn
RATE_LIMIT_MAX_REQUESTS=50  # Plus strict
```

---

## Changement de Provider en Production

**Z√©ro Downtime :**

1. Mettre √† jour `.env` :
```env
AI_PROVIDER=claude
ANTHROPIC_API_KEY=nouvelle-cl√©
```

2. Red√©marrer l'app :
```bash
# Docker
docker-compose restart app

# PM2
pm2 restart alfred

# Kubernetes
kubectl rollout restart deployment/alfred
```

**C'est tout ! Aucun code √† modifier.**

---

## V√©rification Configuration

V√©rifier que votre configuration fonctionne :

```bash
# 1. D√©marrer l'app
npm run dev

# 2. Tester l'API
curl http://localhost:3000/api/styles

# Si √ßa marche, la config DB est OK ‚úÖ

# 3. S'inscrire + cr√©er document + analyser
# Si l'analyse fonctionne, la config IA est OK ‚úÖ
```

---

## S√©curit√©

### ‚ö†Ô∏è IMPORTANT

- **Jamais** commit `.env` dans Git
- **Jamais** hardcoder les API keys dans le code
- **Changer** `JWT_SECRET` en production
- **Utiliser** des secrets managers en prod (AWS Secrets, Vault, etc.)
- **Limiter** les permissions des API keys (read-only si possible)

### Protection `.env`

Le fichier `.gitignore` contient d√©j√† :
```
.env
.env*.local
.env.production
```

---

## Troubleshooting

### "API Key invalide"

- V√©rifier le format de la cl√©
- V√©rifier les quotes dans `.env` (pas de quotes autour des valeurs)
- V√©rifier que le provider correspond √† la cl√©

### "Connection refused Ollama"

```bash
# D√©marrer Ollama
ollama serve

# V√©rifier que √ßa tourne
curl http://localhost:11434/api/version
```

### "Module not found"

```bash
# R√©g√©n√©rer le client Prisma apr√®s changement .env
npm run db:generate
```

---

## Plus d'Informations

- [Architecture](architecture.md) : Pourquoi le pattern Adapter
- [ADR 002](adr/002-ai-providers.md) : D√©cisions sur les providers IA
- [API Documentation](api-documentation.md) : Endpoints disponibles

